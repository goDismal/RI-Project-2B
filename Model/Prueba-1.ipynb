{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\glenn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import faiss\n",
        "import torch\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:3: SyntaxWarning: invalid escape sequence '\\C'\n",
            "<>:3: SyntaxWarning: invalid escape sequence '\\C'\n",
            "C:\\Users\\glenn\\AppData\\Local\\Temp\\ipykernel_29892\\583663975.py:3: SyntaxWarning: invalid escape sequence '\\C'\n",
            "  text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace(\"\\t\", \" \").replace(\"\\C\",\"\")\n"
          ]
        }
      ],
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace(\"\\t\", \" \").replace(\"\\C\",\"\")\n",
        "    text = re.sub(r\"\\[.*?\\]\", \"\", text) \n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_txt_files(folder_path):\n",
        "    df = pd.read_csv(folder_path)\n",
        "    df[\"Entrevista\"] = df[\"Entrevista\"].apply(clean_text)  \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "folder_path = \"../CorpusRI.csv\"\n",
        "df = process_txt_files(folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Cargar el CSV y fragmentar las entrevistas en oraciones\n",
        "def load_and_split_csv(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = process_txt_files(folder_path)\n",
        "    nltk.download('punkt')\n",
        "    df['Oraciones'] = df['Entrevista'].apply(nltk.sent_tokenize)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Generar embeddings con sentence-transformers\n",
        "def generate_embeddings(sentences, model_name='sentence-transformers/all-MiniLM-L6-v2'):\n",
        "    model = SentenceTransformer(model_name)\n",
        "    embeddings = model.encode(sentences, convert_to_tensor=True, normalize_embeddings=True)\n",
        "    return embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Indexar en FAISS\n",
        "def create_faiss_index(embeddings):\n",
        "    d = embeddings.shape[1]  # Dimensión de los embeddings\n",
        "    index = faiss.IndexFlatL2(d)\n",
        "    index.add(embeddings.cpu().numpy())\n",
        "    return index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Recuperar oraciones relevantes\n",
        "def retrieve_similar_sentences(query, model, index, sentences, k=5):\n",
        "    query_embedding = model.encode([query], convert_to_tensor=True, normalize_embeddings=True).cpu().numpy()\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "    return [sentences[i] for i in indices[0]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Generación de texto con Mistral-7B\n",
        "\n",
        "def generate_response(context, query, model_name='mistralai/Mistral-7B-Instruct-v0.1'):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map='auto')\n",
        "    \n",
        "    prompt = f\"Pregunta: {query}\\nContexto relevante: {context}\\nRespuesta: \"\n",
        "    inputs = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
        "    output = model.generate(**inputs, max_new_tokens=200)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\glenn\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "folder_path = r\"C:\\Users\\glenn\\Documents\\Repositories\\RI-Project-2B\\CorpusRI.csv\"  # Ruta al archivo CSV\n",
        "query = \"¿Que opina Leonidas Iza respecto a la delincuencia?\"\n",
        "df = load_and_split_csv(folder_path)\n",
        "sentences = [s for sublist in df['Oraciones'] for s in sublist]  # Lista plana de oraciones\n",
        "\n",
        "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "embeddings = generate_embeddings(sentences, model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "index = create_faiss_index(embeddings)\n",
        "relevant_sentences = retrieve_similar_sentences(query, embedding_model, index, sentences)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "870c1348d63e45bf8cb4ed96aa2aaf80",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Respuesta Generada:\n",
            " Pregunta: ¿Que opina Leonidas Iza respecto a la delincuencia?\n",
            "Contexto relevante: ¿qué opina el respecto? leonidas, usted qué opina del voto nulo? pero es un gusto compartir esta mañana con el ingeniero leonidas iza. algo más que acotar a esta breve descripción de su persona, leonidas. dicen que está fracturada, por ejemplo, con el señor leonidas isa.\n",
            "Respuesta: ¡Hola! ¿Qué puedo hacer para ayudarte hoy?\n"
          ]
        }
      ],
      "source": [
        "response = generate_response(' '.join(relevant_sentences), q<uery)\n",
        "print(\"Respuesta Generada:\\n\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
